{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"results.p\", \"rb+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickler = pickle.Unpickler(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = []\n",
    "for image_path in sorted(glob.glob(\"/home/houcem/Documents/Data/rgb/*.png\")):\n",
    "    image = imageio.imread(image_path) \n",
    "    training_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50V2, MobileNetV2\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten, Concatenate, Reshape, BatchNormalization, Dropout\n",
    "from keras.activations import relu, linear\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50V2(include_top=False, input_tensor=Input(shape=(112,112,3)), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the motor input\n",
    "y = Input(shape=(4,))\n",
    "\n",
    "\n",
    "#Defining the ResNet Encoder input\n",
    "image_input = Input(shape=(112,112,3,))\n",
    "x = resnet(image_input)\n",
    "x = Flatten()(x)\n",
    "\n",
    "#Concatenating both vectors\n",
    "concat = Concatenate()([x, y])\n",
    "\n",
    "z = Dense(64, activation = 'relu')(concat)\n",
    "z = Dense(128, activation = 'relu')(z)\n",
    "z = Dense(512, activation = 'relu')(z)\n",
    "z = Dense(784, activation= 'relu')(z)\n",
    "\n",
    "encoder = Model(inputs= [y, image_input], outputs = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50v2 (Model)              (None, 4, 4, 2048)   23564800    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           resnet50v2[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32772)        0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           2097472     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          8320        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          66048       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 784)          402192      dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,138,832\n",
      "Trainable params: 26,093,392\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_decoder = Input(shape=(784,))\n",
    "\n",
    "d = Reshape((28,28,1))(input_decoder)\n",
    "d = Conv2DTranspose(128,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(128,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(128,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(128,(3, 3), strides=2, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(64,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(64,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(64,(3, 3), strides=1, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(64,(3, 3), strides=2, activation='relu', padding='same')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Conv2DTranspose(32,(3, 3), activation='relu', padding='same')(d)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(d)\n",
    "\n",
    "Decoder = Model(inputs = input_decoder, outputs = decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 56, 56, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 112, 112, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 3)       867       \n",
      "=================================================================\n",
      "Total params: 651,011\n",
      "Trainable params: 649,475\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(112, 112, 3,))\n",
    "motor_input = Input(shape=(4,))\n",
    "Encoded = encoder([motor_input,img_input])\n",
    "Decoded = Decoder(Encoded)\n",
    "\n",
    "autoencoder = Model(inputs = [motor_input,img_input], outputs = Decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data and Splitting the x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_training_x=np.asarray(training_images[0:len(training) -3])\n",
    "motor_training=np.asarray(training[0:len(training) -1])\n",
    "img_training_y=np.asarray(training_images[1:len(training) -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss = 'mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 82s 33ms/step - loss: 9830.1191\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 82s 33ms/step - loss: 9829.8779\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - 82s 33ms/step - loss: 9829.8760\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - 81s 33ms/step - loss: 9829.87990s - loss: 9829.70\n",
      "Epoch 5/20\n",
      "2500/2500 [==============================] - 82s 33ms/step - loss: 9829.8789\n",
      "Epoch 6/20\n",
      "2500/2500 [==============================] - 81s 33ms/step - loss: 9829.8672\n",
      "Epoch 7/20\n",
      "2500/2500 [==============================] - 82s 33ms/step - loss: 9829.87790s - loss: 9830.\n",
      "Epoch 8/20\n",
      "2500/2500 [==============================] - 81s 33ms/step - loss: 9829.8760\n",
      "Epoch 9/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8936\n",
      "Epoch 10/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8926\n",
      "Epoch 11/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8799\n",
      "Epoch 12/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8789\n",
      "Epoch 13/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8711\n",
      "Epoch 14/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8789\n",
      "Epoch 15/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8848\n",
      "Epoch 16/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8682\n",
      "Epoch 17/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8789\n",
      "Epoch 18/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8730\n",
      "Epoch 19/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8789\n",
      "Epoch 20/20\n",
      "2500/2500 [==============================] - 81s 32ms/step - loss: 9829.8613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3350134750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x=[motor_training,img_training_x], y=img_training_y, batch_size=4,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save_weights(\"encoder_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights(\"autoencoder_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
